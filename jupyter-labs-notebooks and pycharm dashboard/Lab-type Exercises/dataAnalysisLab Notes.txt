import pandas as pd
import numpy as np

path='https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-DA0101EN-SkillsNetwork/labs/Data%20files/automobileEDA.csv'
df = pd.read_csv(path)
df.head()

%%capture
! pip install seaborn

import matplotlib.pyplot as plt
import seaborn as sns
%matplotlib inline 

# list the data types for each column
print(df.dtypes)

#Find the correlation between the following columns: bore, stroke, compression-ratio, and horsepower.
# Write your code below and press Shift+Enter to execute 
df[['bore','stroke','compression-ratio','horsepower']].corr()

#positive linear relationship
#Let's find the scatterplot of "engine-size" and "price".
# Engine size as potential predictor variable of price
sns.regplot(x="engine-size", y="price", data=df)
plt.ylim(0,)

#We can examine the correlation between 'engine-size' and 'price' and see that it's approximately 0.87.
df[["engine-size", "price"]].corr()

#Let's find the scatterplot of "highway-mpg" and "price".
sns.regplot(x="highway-mpg", y="price", data=df)

#We can examine the correlation between 'highway-mpg' and 'price' and see it's approximately -0.704.
df[['highway-mpg', 'price']].corr()

#Let's see if "peak-rpm" is a predictor variable of "price".
sns.regplot(x="peak-rpm", y="price", data=df)
#Peak rpm does not seem like a good predictor of the price at all since the regression line is close to horizontal.

#We can examine the correlation between 'peak-rpm' and 'price' and see it's approximately -0.101616.
df[['peak-rpm','price']].corr()

#Find the correlation between x="stroke" and y="price".
df[["stroke","price"]].corr()

#Given the correlation results between "price" and "stroke", do you expect a linear relationship? Verify your results using the function "regplot()".
sns.regplot(x="stroke", y="price", data=df)

#Let's look at the relationship between "body-style" and "price".
sns.boxplot(x="body-style", y="price", data=df)

sns.boxplot(x="engine-location", y="price", data=df)
#Here we see that the distribution of price between these two engine-location categories, front and rear, are distinct enough to take engine-location as a potential good predictor of price.

# drive-wheels
sns.boxplot(x="drive-wheels", y="price", data=df)

#Let's first take a look at the variables by utilizing a description method. The describe function automatically computes basic statistics for all continuous variables. Any NaN values are automatically skipped in these statistics. This will show: the count of that variable, the mean, the standard deviation (std), the minimum value, the IQR (Interquartile Range: 25%, 50% and 75%), the maximum value

df.describe()

#The default setting of "describe" skips variables of type object. We can apply the method "describe" on the variables of type 'object' as follows:
df.describe(include=['object'])

#Value counts is a good way of understanding how many units of each characteristic/variable we have..  Donâ€™t forget the method "value_counts" only works on pandas series, not pandas dataframes. As a result, we only include one bracket df['drive-wheels'], not two brackets df[['drive-wheels']].
df['drive-wheels'].value_counts()
#We can convert the series to a dataframe as follows:
df['drive-wheels'].value_counts().to_frame()

#Let's repeat the above steps but save the results to the dataframe "drive_wheels_counts" and rename the column 'drive-wheels' to 'value_counts'. and rename index to drive-wheels:
drive_wheels_counts = df['drive-wheels'].value_counts().to_frame()
drive_wheels_counts.rename(columns={'drive-wheels': 'value_counts'}, inplace=True)
drive_wheels_counts

drive_wheels_counts.index.name = 'drive-wheels'
drive_wheels_counts

#for engine location:
# engine-location as variable
engine_loc_counts = df['engine-location'].value_counts().to_frame()
engine_loc_counts.rename(columns={'engine-location': 'value_counts'}, inplace=True)
engine_loc_counts.index.name = 'engine-location'
engine_loc_counts.head(10)

df['drive-wheels'].unique() #group by variable

#select columns assign to group
df_group_one = df[['drive-wheels','body-style','price']]
#We can then calculate the average price for each of the different categories of data.
# grouping results
df_group_one = df_group_one.groupby(['drive-wheels'],as_index=False).mean()
df_group_one

# grouping results
df_gptest = df[['drive-wheels','body-style','price']]
grouped_test1 = df_gptest.groupby(['drive-wheels','body-style'],as_index=False).mean()
grouped_test1

#pivot table
grouped_pivot = grouped_test1.pivot(index='drive-wheels',columns='body-style')
grouped_pivot

#Often, we won't have data for some of the pivot cells. We can fill these missing cells with the value 0, but any other value could potentially be used as well. It should be mentioned that missing data is quite a complex subject and is an entire course on its own.
grouped_pivot = grouped_pivot.fillna(0) #fill missing values with 0
grouped_pivot

#Use the "groupby" function to find the average "price" of each car based on "body-style".
# grouping results
df_gptest2 = df[['body-style','price']]
grouped_test_bodystyle = df_gptest2.groupby(['body-style'],as_index= False).mean()
grouped_test_bodystyle

#heat map
#use the grouped results
plt.pcolor(grouped_pivot, cmap='RdBu')
plt.colorbar()
plt.show()

#Correlation: a measure of the extent of interdependence between variables. Causation: the relationship between cause and effect between two variables. The Pearson Correlation measures the linear dependence between two variables X and Y. The resulting coefficient is a value between -1 and 1 inclusive, where: 1: Perfect positive linear correlation. 0: No linear correlation, the two variables most likely do not affect each other. -1: Perfect negative linear correlation.

#remember that pearson corr is: df.corr()
#What is this P-value? The P-value is the probability value that the correlation between these two variables is statistically significant. Normally, we choose a significance level of 0.05, which means that we are 95% confident that the correlation between the variables is significant.

By convention, when the

p-value is  <  0.001: we say there is strong evidence that the correlation is significant.
the p-value is  <  0.05: there is moderate evidence that the correlation is significant.
the p-value is  <  0.1: there is weak evidence that the correlation is significant.
the p-value is  >  0.1: there is no evidence that the correlation is significant.

from scipy import stats
pearson_coef, p_value = stats.pearsonr(df['wheel-base'], df['price'])
print("The Pearson Correlation Coefficient is", pearson_coef, " with a P-value of P =", p_value)  

#Conclusion:
Since the p-value is  <  0.001, the correlation between wheel-base and price is statistically significant, although the linear relationship isn't extremely strong (~0.585).

#The Analysis of Variance (ANOVA) is a statistical method used to test whether there are significant differences between the means of two or more groups. ANOVA returns two parameters:

F-test score: ANOVA assumes the means of all groups are the same, calculates how much the actual means deviate from the assumption, and reports it as the F-test score. A larger score means there is a larger difference between the means.

P-value: P-value tells how statistically significant our calculated score value is.

If our price variable is strongly correlated with the variable we are analyzing, we expect ANOVA to return a sizeable F-test score and a small p-value.